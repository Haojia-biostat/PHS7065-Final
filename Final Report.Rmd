---
title: "Prediction-Powered Inference Framework Under Covariate Shift"
subtitle: "PHS 7065 Fall 2024 - Final Report"
author: |
  | Instructor: Dr. Xuan Wang
  | Group Members: Yingjia Wei, Haojia Li
geometry: margin=2.5cm
output: 
  pdf_document:
    toc: true
    number_sections: true
date: "2024-12-14"
bibliography: references.bib
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,warning = F, message = F, cache = F)
options(knitr.kable.NA = "")
options(digits = 4)
```

```{r load packages}
library(tidyverse)
```

\newpage
# Introduction

A substantial proportion of missing data is a common challenge in Electronic Health Records (EHR) data analysis, which has the potential to undermine the validity of research findings [@sterne_multiple_2009].
Machine learning algorithms can be employed to predict missing values based on observed data. 
However, questions remain about the validity of conclusions drawn from such predicted data. 
To address this concern, @angelopoulos_prediction-powered_2023 proposed Prediction-Powered Inference (PPI), a framework designed to enable provably valid statistical inference when predictions are used as data.
The PPI method leverages a gold-standard dataset, consisting of features paired with observed outcomes, to quantify and correct errors made by the machine-learning algorithm on the unlabeled dataset. 
This allows the constructed confidence intervals to achieve the best between two extremes: using only labeled data and relying solely on predicted unlabeled data:
(1) the intervals are valid, as they contain the true value of the estimand of interest, and 
(2) they are more efficient, with narrower widths achieved by incorporating information from the larger sample size of unlabeled data.

Despite its advantages, the PPI framework has notable limitations. 
When the provided predictions are inaccurate, the constructed intervals can perform worse than the "classical intervals" derived solely from labeled data. 
To improve the statistical efficiency of PPI, @angelopoulos_ppi_2024 developed Efficient Prediction-Powered Inference (PPI++), 
which incorporates a weighting parameter, $\lambda$, to minimize the asymptotic variance of the prediction-powered estimator. 
Additionally, @zrnic_cross-prediction-powered_2024 proposed Cross-Prediction-Powered Inference (Cross-PPI), an extension of PPI that ensures validity by splitting the labeled data to train the predictive model.

Our study aims to evaluate the performance of the PPI, PPI++, Cross-PPI, and the combination of PPI++ and Cross-PPI (Cross-PPI++) methods through a comprehensive simulation study. 
Specifically, we will examine their statistical properties, including the validity and efficiency of the constructed confidence intervals, under various simulated scenarios. 
Initially, we will evaluate these methods in settings where the labeled and unlabeled data are drawn from the same distribution. 
Furthermore, we will expand our focus to include the common challenge in EHR data analysis known as covariate shift, where the distribution of labeled data differs from that of unlabeled data. 
To address this, we will incorporate the density ratio into the PPI methods.

In the simulation study, we will focus on the simplest estimand, the mean outcome, and evaluate the performance of these methods across various settings, 
including different ratios of labeled to unlabeled data, varying levels of predictive model accuracy, diverse feature distributions, and degrees of covariate shift. 
The simulation will be replicated 100 times, and performance metrics will include the coverage probability of confidence intervals, the mean width of intervals. 
By systematically exploring these scenarios, we aim to identify the conditions under which each method performs optimally or encounters limitations, offering practical guidance for their application in real-world EHR datasets.

# Simulation Study

## Simulation Assuming IID Data

When $(X,Y)$ and $(\tilde X, \tilde Y)$ are are independently and identically distributed (i.i.d.), the performance of PPI methods depends on two key factors: 

1. The relative size of $N$ (unlabeled data) compared to $n$ (labeled data).
The accuracy of the prediction model.
2. The accuracy of the prediction model.

To evaluate these factors, we designed a simulation study with the following settings:

- **Unlabeled data size $N$:** fixed at 10000.
- **Labeled data size $n$:** varied across 100, 200, 500, 1000, 2000, 3000, 4000, 5000.
- **Prediction model:** A linear regression model defined as:

    $$
    Y = 1 + 2X_1 + 3X_2 + \epsilon
    $$

    where $X_1 \sim N(0,1)$, $X_2 \sim Bernoulli(0.5)$, and $\epsilon \sim N(0,\sigma_e^2)$. Here, $X_1$ and $X_2$ are independent.

- **Noise level $\sigma_e$:** set to 0.1, 1, 2, 5.

- **Predicted values $\hat Y$:**

  - For PPI and PPI++, $\hat Y$ is computed from linear models trained on the labeled data.
  - For Cross-PPI and Cross-PPI++, $\hat Y$ obtained from cross-predictions using $K=5$ folds.
      
- **Simulation replications:** each scenario is replicated 100 times, and all results are averaged over these replications.

- **Performance metrics:** we evaluate the performance of PPI methods using the following metrics:
  
  1. **Mean width of confidence intervals:** A measure of efficiency, where narrower intervals indicate better precision.
  2. **Coverage probability:** proportion of confidence intervals that include the true parameter value, where higher values indicate that the method produces valid intervals that reliably capture the true value.
  
## Simulation Under Covariate Shift

When the distribution of $(X,Y)$ and $(\tilde X, \tilde Y)$ is different, the performance of PPI methods can be affected by the covariate shift. We tested the performance of PPI methods incorporating the density ratio $w(X)$ under three different scenarios:

1. In the unlabeled data, $X_1 \sim N(\mu_1,\sigma_0^2), \text{ where } \mu_1=0.2,1,2, \text{ and } X_2 \sim Bernoulli(p_0)$. 
The distribution of $X_1$ undergoes a location shift to the right as $\mu_1$ increase, while its overall shape remains unchanged. 
In this case, the density ratio is: 

$$
w(x) = \frac{\tilde p(x)}{p(x)} = \exp \left\{\frac{1}{2\sigma_0^2}  (2x_1-\mu_1-\mu_0)(\mu_1 -\mu_0)  \right\},
$$

  which exhibits an exponential growth pattern as $X_1$ increase, particularly for larger values of $X_1$.
  This behavior indicates that the discrepancy between the distributions of labeled and unlabeled data becomes increasingly pronounced in the tails.

```{r}
set.seed(2034)
s1 <- data.frame(labeled=rnorm(100000,0,1), 
                 mu1=rnorm(100000,0.2,1), 
                 mu2=rnorm(100000,1,1), 
                 mu3=rnorm(100000,2,1))

w1 <- function(x1, mu_1, mu_0, sigma_0, truncation = NULL){
  w <- exp((1/(2*sigma_0^2))*(2*x1-mu_1-mu_0)*(mu_1-mu_0))
  if(!is.null(truncation)) w[w > truncation] <- truncation
  return(w)
}

s1$w1 <- w1(s1$labeled, 0.2, 0, 1)
s1$w2 <- w1(s1$labeled, 1, 0, 1)
s1$w3 <- w1(s1$labeled, 2, 0, 1)

ps1a <- ggplot() +
  geom_density(aes(x=labeled), data = s1, color = "black", fill = "black", alpha = 0.3) +
  geom_density(aes(x=mu1), data = s1, color = "cyan", fill = "cyan", alpha = 0.3) +
  geom_density(aes(x=mu2), data = s1, color = "pink", fill = "pink", alpha = 0.3) +
  geom_density(aes(x=mu3), data = s1, color = "purple", fill = "purple", alpha = 0.3) +
  labs(y = "Density", x = "") +
  theme_bw() +
  scale_x_continuous(expand = c(0,0), limits = c(-4,4)) +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5))

ps1b <- ggplot() + 
  geom_line(aes(x=labeled, y=w1), data = s1, color = "cyan") +
  geom_line(aes(x=labeled, y=w2), data = s1, color = "pink") +
  geom_line(aes(x=labeled, y=w3), data = s1, color = "purple") +
  ylim(c(0, 300)) +
  labs(x="Labeled X1", y="Density ratio, w(X1)")+
  theme_bw() +
  scale_x_continuous(expand = c(0,0), limits = c(-4,4)) +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5))

ggpubr::ggarrange(ps1a, ps1b, ncol = 1)

```

2. $X_1 \sim N(\mu_0,\sigma_1^2), \text{ where } \sigma_1=0.1,0.5,2, \text{ and } X_2 \sim Bernoulli(p_0)$. In this case, the density ratio is: 

$$
w(x) = \frac{\tilde p(x)}{p(x)} = \frac{\sigma_0}{\sigma_1} \exp \left\{ -\frac{1}{2} \left( \frac{1}{\sigma_1^2} - \frac{1}{\sigma_0^2} \right) (x_1-\mu_0)^2 \right\}
$$

  When $\sigma_1 < \sigma_0$, the density ratio shows sharp peaks near the center and approaches zero in the tails due to the tighter concentration of the unlabeled data.
  Conversely, when $\sigma_1 > \sigma_0$, the density ratio flattens and increases exponentially at the tails, as the unlabeled data becomes more dispersed relative to the labeled data.

```{r}
set.seed(2034)
s2 <- data.frame(labeled=rnorm(100000,0,1), 
                 mu1=rnorm(100000,0,0.1), 
                 mu2=rnorm(100000,0,0.5), 
                 mu3=rnorm(100000,0,2)) 

w2 <- function(x1, sigma_1, mu_0, sigma_0, truncation = NULL){
  w <- (sigma_0/sigma_1)*exp(-0.5*((1/sigma_1^2)-(1/sigma_0^2))*(x1-mu_0)^2)
  if(!is.null(truncation)) w[w > truncation] <- truncation
  return(w)
}

s2$w1 <- w2(s2$labeled, 0.1, 0, 1)
s2$w2 <- w2(s2$labeled, 0.5, 0, 1)
s2$w3 <- w2(s2$labeled, 2, 0, 1)

ps2a <- ggplot() +
  geom_density(aes(x=labeled), data = s2, color = "black", fill = "black", alpha = 0.3) +
  geom_density(aes(x=mu1), data = s2, color = "cyan", fill = "cyan", alpha = 0.3) +
  geom_density(aes(x=mu2), data = s2, color = "pink", fill = "pink", alpha = 0.3) +
  geom_density(aes(x=mu3), data = s2, color = "purple", fill = "purple", alpha = 0.3) +
  
  labs(y = "Density", x = "") +
  theme_bw() +
  scale_x_continuous(expand = c(0,0), limits = c(-4,4)) +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5))

ps2b <- ggplot() + 
  geom_line(aes(x=labeled, y=w1), data = s2, color = "cyan") +
  geom_line(aes(x=labeled, y=w2), data = s2, color = "pink") +
  geom_line(aes(x=labeled, y=w3), data = s2, color = "purple") +
  ylim(c(0, 200)) +
  labs(x="Labeled X1", y="Density ratio")+
  theme_bw() + 
  labs(x="Labeled X1", y="Density ratio, w(X1)")+
  theme_bw() +
  scale_x_continuous(expand = c(0,0), limits = c(-4,4)) +
  theme(axis.text.y = element_text(angle = 90, hjust = 0.5))

ggpubr::ggarrange(ps2a, ps2b, ncol = 1)

```

3. $X_1 \sim N(\mu_0,\sigma_0^2), \text{ and } X_2 \sim Bernoulli(p_1), \text{ where } p_1=0.55, 0.7, 0.85$. In this case, the density ratio is: 

$$
w(x) = \frac{\tilde p(x)}{p(x)} = \left( \frac{p_1}{p_0} \right)^{x_2} \left( \frac {1-p_1}{1-p_0}\right)^{1-x_2}
$$

  The density ratios remain within a limited range compared to the potentially unbounded growth of density ratios seen in normal distributions under covariate shift.

```{r}
w3 <- function(x2, p_1, p_0, truncation = NULL){
  w <- (p_1/p_0)^x2*((1-p_1)/(1-p_0))^(1-x2)
  if(!is.null(truncation)) w[w > truncation] <- truncation
  return(w)
}
p1 <- c(0.55, 0.7, 0.85)
p0 <- 0.5
w0 <- sapply(p1, \(p) w3(0, p, p0))
w1 <- sapply(p1, \(p) w3(1, p, p0))
data.frame(p1, w0, w1) |>
  knitr::kable(col.names = c("p1", "w(X2=0)", "w(X2=1)")) |>
  kableExtra::kable_styling(full_width = F)

```

# Results

## Performance of PPI Methods Without Covariate Shift

```{r}
iid_simulation <- readRDS("iid_simulation.rds")
```

## Performance of PPI Methods Under Covariate Shift

```{r}
covshift_simulation <- readRDS("covshift_simulation.rds")
covshift_settings <- covshift_simulation[[1]] |> select(n:scenario, method)

# mean width of CI
covshift_ci_width_100 <- do.call(
  cbind, 
  lapply(covshift_simulation, \(x) x$ci_width)
  ) |> as.data.frame()
covshift_ci_width_summary <- data.frame(
  covshift_settings,
  ci_width_mean = apply(covshift_ci_width_100, 1, mean, na.rm = T),
  ci_width_sd = apply(covshift_ci_width_100, 1, sd, na.rm = T)
)

# coverage probability
covshift_coverage_100 <- do.call(
  cbind, 
  lapply(covshift_simulation, \(x) x$coverage)
  ) |> as.data.frame()
covshift_coverage_summary <- data.frame(
  covshift_settings,
  coverage_mean = apply(covshift_coverage_100, 1, mean, na.rm = T),
  coverage_sd = apply(covshift_coverage_100, 1, sd, na.rm = T)
)

covshift_ci_width_coverage_summary <- merge(covshift_ci_width_summary, covshift_coverage_summary)
covshift_ci_width_coverage_summary <- covshift_ci_width_coverage_summary |>
  select(-N, -ci_width_sd, -coverage_sd) |>
  gather(key = "performance", value = "value", -n, -noise_level, -mu, -sigma, -p, -scenario, -method) |>
  mutate(noise_level = factor(
    noise_level, 
    levels = c(0.1, 1, 2, 5), 
    labels = paste("Noise level =", c(0.1, 1, 2, 5)))
    ) |>
  mutate(Method = factor(
    method, 
    levels = c("classical CLT", "standard PPI", "PPI++, no density ratio", "PPI++", "Cross PPI++"), 
    labels = c("Classical Inference (lambda = 0)", 
               "Standard PPI (lambda = 1)", 
               "PPI++, no density ratio (w(X) = 1)", 
               "PPI++", 
               "Cross-PPI++")
    )) |>
  mutate(performance = factor(
    performance, 
    levels = c("ci_width_mean", "coverage_mean"), 
    labels = c("CI width", "Coverage rate")
    ))

performance_visual <- function(df) {
  df |>
    ggplot(aes(x = n, y = value, color = Method)) +
    geom_line() +
    geom_point() +
    facet_grid(cols = vars(performance), rows = vars(noise_level), scales = "free_y") +
    theme_bw() +
    labs(y = "Performance over 100 replications", x = "Sample size in labeled data (n)") +
    theme(
      legend.position = "bottom", legend.title = element_blank(), 
      legend.margin = margin(0,0,0,0, "pt"), legend.key.spacing.y = unit(0, "pt")
    ) +
    guides(color = guide_legend(nrow = 2, byrow = TRUE))
}


```

# References

::: {#refs}
:::

# Appendix

## Main Code Chunks

```{r settings, echo=TRUE, eval=FALSE}
# simulation settings

# basic settings in iid simulation
# unlabeled data size
N <- 10000
# labeled data size
n <- c(100, 200, 500, 1000, 2000, 3000, 4000, 5000)
# distribution parameters for X1 and X2 in labeled data
mu_0 <- 0
sigma_0 <- 1
p_0 <- 0.5
# noise level
sigma_e <- c(0.1, 1, 2, 5)
# number of folds for cross-fit
K <- 5
# number of replications
B <- 100
# combine iid settings
iid_settings <- expand.grid(n = n, N = N, sigma_e = sigma_e)

# additional settings under covariate shift
# distribution parameters for X1 and X2 in unlabeled data
mu_1 <- c(0.2, 1, 2)
sigma_1 <- c(0.1, 0.5, 2)
p_1 <- c(0.55, 0.7, 0.85)

# parameter combinations
param_comb <- rbind(
  # scenario 1: covariate shift in X1 with mu changed
  data.frame(mu = mu_1, sigma = sigma_0, p = p_0, scenario = "Scenario 1"),
  # scenario 2: covariate shift in X1 with sigma changed
  data.frame(mu = mu_0, sigma = sigma_1, p = p_0, scenario = "Scenario 2"),
  # scenario 3: covariate shift in X2 with p changed
  data.frame(mu = mu_0, sigma = sigma_0, p = p_1, scenario = "Scenario 3")
)
covshift_settings <- merge(expand.grid(n = n, N = N, sigma_e = sigma_e), param_comb, all = T)

```

```{r functions, echo=TRUE, eval=FALSE}
# functions used in simulation

# define function to generate a single dataset
gen_data <- function(
    size,       # sample size
    mu, sigma,  # for X1
    p,          # for X2
    sigma_e # for epsilon
){
  X1 <- rnorm(size, mu, sigma)
  X2 <- rbinom(size, 1, p)
  Y <- 1 + 2*X1 + 3*X2 + rnorm(size, 0, sigma_e)
  return(data.frame(
    X1 = X1,
    X2 = X2,
    Y = Y
  ))
}

# density functions
w1 <- function(x1, mu_1, mu_0, sigma_0, truncation = NULL){
  w <- exp((1/(2*sigma_0^2))*(2*x1-mu_1-mu_0)*(mu_1-mu_0))
  if(!is.null(truncation)) w[w > truncation] <- truncation
  return(w)
}
w2 <- function(x1, sigma_1, mu_0, sigma_0, truncation = NULL){
  w <- (sigma_0/sigma_1)*exp(-0.5*((1/sigma_1^2)-(1/sigma_0^2))*(x1-mu_0)^2)
  if(!is.null(truncation)) w[w > truncation] <- truncation
  return(w)
}
w3 <- function(x2, p_1, p_0, truncation = NULL){
  w <- (p_1/p_0)^x2*((1-p_1)/(1-p_0))^(1-x2)
  if(!is.null(truncation)) w[w > truncation] <- truncation
  return(w)
}


# define function to combine labeled and unlabeled data
comb_data <- function(
    n, N,               # sample sizes
    mu_0, sigma_0, p_0, # X distribution in labeled data
    mu_1, sigma_1, p_1, # X distribution in unlabeled data
    sigma_e,            # noise level
    truncation = NULL   # truncation for weights
){
  # labeled data
  labeled_data <- gen_data(n, mu_0, sigma_0, p_0, sigma_e)
  # unlabeled data
  unlabeled_data <- gen_data(N, mu_1, sigma_1, p_1, sigma_e)
  
  # fit model
  fit <- lm(Y ~ X1 + X2, data = labeled_data)
  labeled_data$Y_hat <- predict(fit, labeled_data[,1:2])
  unlabeled_data$Y_hat <- predict(fit, unlabeled_data[,1:2])
  
  labeled_data$w <- 1
  # add weight
  if(mu_0 != mu_1){
    labeled_data$w <- w1(
      labeled_data$X1, 
      mu_1 = mu_1, 
      mu_0 = mu_0, 
      sigma_0 = sigma_0, 
      truncation = truncation
      )
  }
  if(sigma_0 != sigma_1){
    labeled_data$w <- w2(
      labeled_data$X1, 
      sigma_1 = sigma_1, 
      mu_0 = mu_0, 
      sigma_0 = sigma_0, 
      truncation = truncation
      )
  }
  if(p_0 != p_1){
    labeled_data$w <- w3(
      labeled_data$X2, 
      p_1 = p_1, 
      p_0 = p_0, 
      truncation = truncation
      )
  }
  
  # generate output
  return(list(
    settings = c(
      n = n, N = N, 
      mu_0 = mu_0, sigma_0 = sigma_0, p_0 = p_0, 
      mu_1 = mu_1, sigma_1 = sigma_1, p_1 = p_1, 
      sigma_e = sigma_e
    ),
    labeled = labeled_data,
    unlabeled = unlabeled_data
  ))
}

# ---- ppi++ ----
lambda_ppi <- function(n, N, Y_n, Y_hat_n, Y_hat_N, w){
  cov <- cov(w*Y_n, w*Y_hat_n)
  var_N <- var(Y_hat_N)
  var_n <- var(w*Y_hat_n)
  lam <- cov/n/(var_N/N+var_n/n)
  return(lam)
}
pointest_ppi <- function(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w){
  mean(w*Y_n) + lam*mean(unlist(Y_hat_N)) - lam*mean(Y_hat_n*w)
}
std_ppi <- function(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w){
  Y_hat_N_var <- var(lam*Y_hat_N)/N
  rectifier_var <- var(w*(Y_n-lam*Y_hat_n))/n
  std <- sqrt(Y_hat_N_var+rectifier_var)
  return(std)
}
ci_ppi <- function(pointest, std, alpha) {
  z <- qnorm(1-alpha/2)
  ll <- pointest - z*std
  ul <- pointest + z*std
  return(c(ll, ul))
}
gen_res <- function(n, N, Y_n, Y_hat_n, Y_N, Y_hat_N, w, lam = NULL, alpha = 0.5) {
  if(is.null(lam)) {
    lam <- lambda_ppi(n, N, Y_n, Y_hat_n, Y_hat_N, w)
  }
  pointest <- pointest_ppi(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w)
  std <- std_ppi(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w)
  ci <- ci_ppi(pointest, std, alpha)
  return(c(
    lam = lam,
    truemean = mean(Y_N),
    pointest = pointest,
    std = std,
    ll = ci[1],
    ul = ci[2],
    ci_width = ci[2] - ci[1],
    coverage = (ci[1] <= mean(Y_N) & mean(Y_N) <= ci[2])
  ))
}

# ---- cross ppi++ ----
lambda_ppi_cross <- function(n, N, Y_n, Y_hat_n, Y_hat_N, w, K, fold){
  cov <- 
    sum(sapply(1:K, \(j) cov(w[fold == j]*Y_n[fold == j], w[fold == j]*Y_hat_n[fold == j])) * 
          tapply(fold, fold, length)) / n
  var_N <- sum(apply(Y_hat_N, 2, var)) / (K^2)
  var_n <- sum(sapply(1:K, \(j) var(w[fold == j]*Y_hat_n[fold == j])) * 
                 tapply(fold, fold, length)) / n
  lam <- cov/n/(var_N/N+var_n/n)
  return(lam)
}
std_ppi_cross <- function(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w, K, fold){
  Y_hat_N_var <- sum(apply(Y_hat_N, 2, var)) *lam^2 / (K^2*N)
  rectifier_var <- 
    sum(sapply(1:K, \(j) var(w[fold == j]*(Y_n[fold == j] - lam*Y_hat_n[fold == j]))) * 
          tapply(fold, fold, length)) / (n^2)
  std <- sqrt(Y_hat_N_var+rectifier_var)
  return(std)
}
gen_res_cross <- function(n, N, Y_n, Y_hat_n, Y_N, Y_hat_N, w, K, fold, lam = NULL, alpha = 0.5) {
  if(is.null(lam)) {
    lam <- lambda_ppi_cross(n, N, Y_n, Y_hat_n, Y_hat_N, w, K, fold)
  }
  pointest <- pointest_ppi(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w)
  std <- std_ppi_cross(lam, n, N, Y_n, Y_hat_n, Y_hat_N, w, K, fold)
  ci <- ci_ppi(pointest, std, alpha)
  return(c(
    lam = lam,
    truemean = mean(Y_N),
    pointest = pointest,
    std = std,
    ll = ci[1],
    ul = ci[2],
    ci_width = ci[2] - ci[1],
    coverage = (ci[1] <= mean(Y_N) & mean(Y_N) <= ci[2])
  ))
}
```

```{r iid simulation, echo=TRUE, eval=FALSE}
library(parallel)
# number of cores
num_cores <- detectCores()-1
# create cluster
cl <- makeCluster(num_cores)

# export data and functions to cluster
clusterExport(cl, c(
  "iid_settings", "B", "K", "mu_0", "sigma_0", "p_0", "K", "B",
  "gen_data", "comb_data",
  "lambda_ppi", "std_ppi", "gen_res",
  "lambda_ppi_cross", "std_ppi_cross", "gen_res_cross",
  "pointest_ppi", "ci_ppi"
))

set.seed(7065)
# run simulation in parallel
iid_simulation <- parLapply(cl, 1:B, function(i){
  combined_data_list <- mapply(
    comb_data, 
    iid_settings$n, 
    iid_settings$N, 
    mu_0, sigma_0, p_0,
    mu_0, sigma_0, p_0,
    iid_settings$sigma_e, 
    SIMPLIFY = F
  )
  
  # ---- PPI ----
  lam0_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$unlabeled$Y_hat,
      w = x$labeled$w,
      lam = 0,
      alpha = 0.05
    )
  )
  lam1_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$unlabeled$Y_hat,
      w = x$labeled$w,
      lam = 1,
      alpha = 0.05
    )
  )
  lamopt_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$unlabeled$Y_hat,
      w = x$labeled$w,
      alpha = 0.05
    )
  )
  
  # ---- Cross-PPI ----
  # add K to labeled data
  combined_data_list_cross <- lapply(
    combined_data_list,
    \(x) {
      x$labeled$fold <- sample(1:K, nrow(x$labeled), replace = TRUE)
      return(x)
    }
  )
  # predict Y_hat_N by K models
  combined_data_list_cross <- lapply(
    combined_data_list_cross,
    \(x) {
      labeled <- x$labeled
      fit_list <- lapply(
        1:K,
        \(j) lm(Y ~ X1+X2, data = labeled, subset = fold == j)
      )
      k_coef <- sapply(fit_list, unlist(coef)) |> t() |> as.data.frame()
      labeled$Y_hat <- apply(labeled, 1, \(obs) {
        coef <- k_coef[obs["fold"],] |> unlist()
        coef[1] + coef[2]*obs["X1"] + coef[3]*obs["X2"]
      })
      
      unlabeled <- x$unlabeled
      Y_hat_N <- data.frame(lapply(
        fit_list,
        \(fit) predict(fit, newdata = unlabeled[,1:2])
      ))
      
      x <- list(
        settings = x[["settings"]], 
        labeled = labeled, 
        unlabeled = x[["unlabeled"]], 
        coef = k_coef, 
        Y_hat_N = Y_hat_N
      )
      return(x)
    }
  )
  
  lam1_ppi_res_cross <- sapply(
    combined_data_list_cross,
    \(x) gen_res_cross(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$Y_hat_N,
      w = x$labeled$w,
      K = K,
      fold = x$labeled$fold,
      lam = 1,
      alpha = 0.05
    )
  )
  lamopt_ppi_res_cross <- sapply(
    combined_data_list_cross,
    \(x) gen_res_cross(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$Y_hat_N,
      w = x$labeled$w,
      K = K,
      fold = x$labeled$fold,
      alpha = 0.05
    )
  )
  
  # ---- combine results ----
  # CLT
  res_summary_lam0 <- data.frame(
    iid_settings,
    t(lam0_ppi_res) |> as.data.frame()
  )
  # standard PPI
  res_summary_lam1 <- data.frame(
    iid_settings,
    t(lam1_ppi_res) |> as.data.frame()
  )
  # PPI++
  res_summary_lamopt <- data.frame(
    iid_settings,
    t(lamopt_ppi_res) |> as.data.frame()
  )
  # Cross-PPI
  res_summary_lam1_cross <- data.frame(
    iid_settings,
    t(lam1_ppi_res_cross) |> as.data.frame()
  )
  # Cross-PPI++
  res_summary_lamopt_cross <- data.frame(
    iid_settings,
    t(lamopt_ppi_res_cross) |> as.data.frame()
  )
  
  colnames(res_summary_lam0) <- 
    colnames(res_summary_lam1) <- 
    colnames(res_summary_lamopt) <- 
    colnames(res_summary_lam1_cross) <-
    colnames(res_summary_lamopt_cross) <- 
    c("n", "N", "noise_level", "lam", 
      "truemean", "pointest", "std", "ll", "ul", 
      "ci_width", "coverage")
  res_summary_all <- rbind(
    cbind(res_summary_lam0, method = "classical CLT"),
    cbind(res_summary_lam1, method = "standard PPI"),
    cbind(res_summary_lamopt, method = "PPI++"),
    cbind(res_summary_lam1_cross, method = "Cross PPI"),
    cbind(res_summary_lamopt_cross, method = "Cross PPI++")
  )
  return(res_summary_all)
})

saveRDS(iid_simulation, "iid_simlation.rds")
stopCluster(cl)
```

```{r covshift simulation, echo=TRUE, eval=FALSE}
library(parallel)
# number of cores
num_cores <- detectCores()-1
# create cluster
cl <- makeCluster(num_cores)

# export data and functions to cluster
clusterExport(cl, c(
  "covshift_settings", "B", "K", "mu_0", "sigma_0", "p_0", "K", "B",
  "gen_data", "comb_data", "w1", "w2", "w3",
  "lambda_ppi", "std_ppi", "gen_res",
  "lambda_ppi_cross", "std_ppi_cross", "gen_res_cross",
  "pointest_ppi", "ci_ppi"
))

set.seed(7065)
# run simulation in parallel
covshift_simulation <- parLapply(cl, 1:B, function(i){
  combined_data_list <- mapply(
    comb_data, 
    covshift_settings$n, 
    covshift_settings$N, 
    mu_0, sigma_0, p_0,
    covshift_settings$mu,
    covshift_settings$sigma,
    covshift_settings$p,
    covshift_settings$sigma_e, 
    SIMPLIFY = F
  )
  
  # ---- PPI ----
  lam0_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$unlabeled$Y_hat,
      w = x$labeled$w,
      lam = 0,
      alpha = 0.05
    )
  )
  lam1_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$unlabeled$Y_hat,
      w = x$labeled$w,
      lam = 1,
      alpha = 0.05
    )
  )
  lamopt_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$unlabeled$Y_hat,
      w = x$labeled$w,
      alpha = 0.05
    )
  )
  lamopt_nodensratio_ppi_res <- sapply(
    combined_data_list,
    \(x) gen_res(
        n = x$settings["n"],
        N = x$settings["N"],
        Y_n = x$labeled$Y,
        Y_hat_n = x$labeled$Y_hat,
        Y_N = x$unlabeled$Y,
        Y_hat_N = x$unlabeled$Y_hat,
        w = 1,
        alpha = 0.05
      )
  )
  
  # ---- Cross-PPI ----
  # add K to labeled data
  combined_data_list_cross <- lapply(
    combined_data_list,
    \(x) {
      x$labeled$fold <- sample(1:K, nrow(x$labeled), replace = TRUE)
      return(x)
    }
  )
  # predict Y_hat_N by K models
  combined_data_list_cross <- lapply(
    combined_data_list_cross,
    \(x) {
      labeled <- x$labeled
      fit_list <- lapply(
        1:K,
        \(j) lm(Y ~ X1+X2, data = labeled, subset = fold == j)
      )
      k_coef <- sapply(fit_list, unlist(coef)) |> t() |> as.data.frame()
      labeled$Y_hat <- apply(labeled, 1, \(obs) {
        coef <- k_coef[obs["fold"],] |> unlist()
        coef[1] + coef[2]*obs["X1"] + coef[3]*obs["X2"]
      })
      
      unlabeled <- x$unlabeled
      Y_hat_N <- data.frame(lapply(
        fit_list,
        \(fit) predict(fit, newdata = unlabeled[,1:2])
      ))
      
      x <- list(
        settings = x[["settings"]], 
        labeled = labeled, 
        unlabeled = x[["unlabeled"]], 
        coef = k_coef, 
        Y_hat_N = Y_hat_N
      )
      return(x)
    }
  )
  
  lamopt_ppi_res_cross <- sapply(
    combined_data_list_cross,
    \(x) gen_res_cross(
      n = x$settings["n"],
      N = x$settings["N"],
      Y_n = x$labeled$Y,
      Y_hat_n = x$labeled$Y_hat,
      Y_N = x$unlabeled$Y,
      Y_hat_N = x$Y_hat_N,
      w = x$labeled$w,
      K = K,
      fold = x$labeled$fold,
      alpha = 0.05
    )
  )
  
  # ---- combine results ----
  # CLT
  res_summary_lam0 <- data.frame(
    covshift_settings,
    t(lam0_ppi_res) |> as.data.frame()
  )
  # standard PPI
  res_summary_lam1 <- data.frame(
    covshift_settings,
    t(lam1_ppi_res) |> as.data.frame()
  )
  # PPI++
  res_summary_lamopt <- data.frame(
    covshift_settings,
    t(lamopt_ppi_res) |> as.data.frame()
  )
  # PPI++, no density ratio
  res_summary_lamopt_nodensratio <- data.frame(
    covshift_settings,
    t(lamopt_nodensratio_ppi_res) |> as.data.frame()
  )
  # Cross-PPI++
  res_summary_lamopt_cross <- data.frame(
    covshift_settings,
    t(lamopt_ppi_res_cross) |> as.data.frame()
  )
  
  colnames(res_summary_lam0) <- 
    colnames(res_summary_lam1) <- 
    colnames(res_summary_lamopt) <- 
    colnames(res_summary_lamopt_nodensratio) <-
    colnames(res_summary_lamopt_cross) <- 
    c("n", "N", "noise_level", "mu", "sigma", "p", "scenario", "lam", 
      "truemean", "pointest", "std", "ll", "ul", 
      "ci_width", "coverage")
  res_summary_all <- rbind(
    cbind(res_summary_lam0, method = "classical CLT"),
    cbind(res_summary_lam1, method = "standard PPI"),
    cbind(res_summary_lamopt, method = "PPI++"),
    cbind(res_summary_lamopt_nodensratio, method = "PPI++, no density ratio"),
    cbind(res_summary_lamopt_cross, method = "Cross PPI++")
  )
  return(res_summary_all)
})

saveRDS(covshift_simulation, "covshift_simlation.rds")
stopCluster(cl)
```

## Results

```{r, fig.height=9, fig.width=8}
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 1", mu == 0.2))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 1", mu == 1))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 1", mu == 2))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 2", sigma == 0.1))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 2", sigma == 0.5))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 2", sigma == 2))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 3", p == 0.55))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 3", p == 0.7))
performance_visual(ci_width_coverage_summary |> filter(scenario == "Scenario 3", p == 0.85))
```